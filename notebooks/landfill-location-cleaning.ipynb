{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import geocoder\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geoencode(address):\n",
    "    '''Get lat/long from Google API\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    address: string,\n",
    "        The address to lookup (ex. 30-27 Greenpoint Avenue LIC, NY)\n",
    "    '''\n",
    "    landfill = \" \".join([address['Facility Address'], address['Town'], ', ', address['State']])\n",
    "\n",
    "    g = geocoder.google(landfill)\n",
    "    \n",
    "    if g.confidence >= 7:\n",
    "        return pd.Series({'lat':g.lat, 'lng':g.lng})\n",
    "    else:\n",
    "        return pd.Series({'lat': None, 'lng': None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Connecticut_Active_Landfills.csv')\n",
    "df['State'] = 'CT'\n",
    "data = pd.concat([df,df.apply(geoencode, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.to_csv('data/Connecticut_Active_Landfills.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_crs = {'init':'epsg:4326'}\n",
    "\n",
    "fpath = ['construction_demo_debris_NYS/construction_demo_debris.shp',\n",
    "         'active_msw_landfills_NYS/active_msw_landfills.shp',\n",
    "         'industrial_commercial_NYS/industrial_commercial.shp',\n",
    "         'Landfill_Sites_in_New_Jersey/Landfill_Sites_in_New_Jersey.shp', \n",
    "         'privately_owned_landfills_NYS/privately_owned_landfills_NYS.shp',\n",
    "         'Connecticut_Active_Landfills.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_geom(coords):\n",
    "    return Point(coords['lng'], coords['lat'])\n",
    "\n",
    "def add_lat_lng(fpath):\n",
    "    fname = os.path.split(fpath)[1]\n",
    "    \n",
    "    if fpath[-3:] == 'csv':\n",
    "        lf = pd.read_csv(fpath)\n",
    "        lf['geometry'] = lf.apply(create_geom, axis=1)\n",
    "        lf = gp.GeoDataFrame(lf)\n",
    "        lf.crs = new_crs\n",
    "        lf = lf.dropna(subset=['lat','lng'])\n",
    "        fname = fname[:-3] + 'shp'\n",
    "    else:\n",
    "        lf = gp.read_file(fpath)  \n",
    "        lf = lf.to_crs(new_crs)\n",
    "        \n",
    "        if 'lat' not in lf.columns or 'lng' not in lf.columns:\n",
    "            lf['lng'] = lf['geometry'].map(lambda point: point.x)\n",
    "            lf['lat'] = lf['geometry'].map(lambda point: point.y)\n",
    "        \n",
    "    fout = os.path.join('data/output', fname)\n",
    "    cols = [n.lower() for n in lf.columns]\n",
    "    lf.columns = cols\n",
    "    lf.to_file(fout)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run\n",
    "[add_lat_lng(os.path.join('data/',i)) for i in fpath]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in glob.glob('data/output/*.shp'):\n",
    "    f = gp.read_file(i)\n",
    "    data.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Clean and Standardize\n",
    "d0 = data[0][['lat','lng','waste_type','name']]\n",
    "d1 = data[1][['lat','lng','waste type','owner']]\n",
    "d2 = data[2][['lat','lng','waste_type','company']]\n",
    "d3 = data[3][['lat','lng','waste_type','company']]\n",
    "d4 = data[4][['lat','lng','lfname']]\n",
    "d5 = data[5][['lat','lng','name']]\n",
    "\n",
    "d1 = d1.rename(columns={'waste type': 'waste_type', 'owner':'name'})\n",
    "\n",
    "d2 = d2.rename(columns={'company':'name'})\n",
    "d3 = d3.rename(columns={'company':'name'})\n",
    "\n",
    "d4 = d4.rename(columns={'lfname':'name'})\n",
    "\n",
    "d4['waste_type'] = 'unknown'\n",
    "d5['waste_type'] = 'unknown'\n",
    "\n",
    "d0['desc'] = 'NY msw'\n",
    "d1['desc'] = 'CT'\n",
    "d2['desc'] = 'NY construction'\n",
    "d3['desc'] = 'NY industrial/commercial'\n",
    "d4['desc'] = 'NJ'\n",
    "d5['desc'] = 'NY private'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.concat([d0,d1,d2,d3,d4,d5], ignore_index=True).to_csv('data/output/landfills_master.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
